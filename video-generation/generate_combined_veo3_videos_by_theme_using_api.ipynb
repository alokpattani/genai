{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "MpvNnbKl0JQx"
      },
      "id": "MpvNnbKl0JQx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "----"
      ],
      "metadata": {
        "id": "O6Gz2XHD--_f"
      },
      "id": "O6Gz2XHD--_f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Google Gen AI SDK for Python"
      ],
      "metadata": {
        "id": "QzUyMXFo7sH8"
      },
      "id": "QzUyMXFo7sH8"
    },
    {
      "cell_type": "code",
      "id": "NllSpyFgOufzqLfcycKbeYHG",
      "metadata": {
        "tags": [],
        "id": "NllSpyFgOufzqLfcycKbeYHG"
      },
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup ffmpeg"
      ],
      "metadata": {
        "id": "aZs1Nd2kAcla"
      },
      "id": "aZs1Nd2kAcla"
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq && apt-get install -y ffmpeg -qq"
      ],
      "metadata": {
        "id": "qFULyBe2AaQn"
      },
      "id": "qFULyBe2AaQn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment."
      ],
      "metadata": {
        "id": "WeSc1cmY7zY7"
      },
      "id": "WeSc1cmY7zY7"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "5nSC28xW71I2"
      },
      "id": "5nSC28xW71I2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "lN2Rym6-75Jm"
      },
      "id": "lN2Rym6-75Jm"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "from IPython.display import Markdown, Video, display\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import concurrent.futures"
      ],
      "metadata": {
        "id": "VMoJ_0um79HH"
      },
      "id": "VMoJ_0um79HH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Google Cloud project information and create client"
      ],
      "metadata": {
        "id": "yT5B5Fsl8CQd"
      },
      "id": "yT5B5Fsl8CQd"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "FZKw3PQ68Aw2"
      },
      "id": "FZKw3PQ68Aw2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a helper function to display media"
      ],
      "metadata": {
        "id": "aNno4TS98DPJ"
      },
      "id": "aNno4TS98DPJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_video(video):\n",
        "    if isinstance(video, str):\n",
        "        file_name = video.split(\"/\")[-1]\n",
        "        !gsutil cp {video} {file_name}\n",
        "        display(Video(file_name, embed=True, width=600))\n",
        "    else:\n",
        "        with open(\"sample.mp4\", \"wb\") as out_file:\n",
        "            out_file.write(video)\n",
        "        display(Video(\"sample.mp4\", embed=True, width=600))"
      ],
      "metadata": {
        "id": "QgNkD16t8BCD"
      },
      "id": "QgNkD16t8BCD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Gemini and video generation models"
      ],
      "metadata": {
        "id": "fgXIWxev9uea"
      },
      "id": "fgXIWxev9uea"
    },
    {
      "cell_type": "code",
      "source": [
        "video_model = \"veo-3.0-generate-001\" #@param{type:\"string\"} [\"veo-3.0-generate-001\", \"veo-3.0-fast-generate-001\"]\n",
        "\n",
        "gemini_model = \"gemini-2.5-flash\" #@param{type:\"string\"} [\"gemini-2.5-flash\", \"gemini-2.5-pro\", \"gemini-2.5-flash-lite\"]"
      ],
      "metadata": {
        "id": "2mGlzlO19unz"
      },
      "id": "2mGlzlO19unz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup elements of desired videos"
      ],
      "metadata": {
        "id": "c6wyoAlXWEsQ"
      },
      "id": "c6wyoAlXWEsQ"
    },
    {
      "cell_type": "code",
      "source": [
        "subject_theme = \"ice cream flavors\" #@param {type:\"string\"}\n",
        "scene_theme = \"fun summertime outdoor environments\" #@param {type:\"string\"}\n",
        "style = \"Photorealistic\"  # @param [\"None\", \"Photorealistic\", \"Cinematic\", \"Vintage\", \"Japanese anime\", \"Claymation\", \"Stop-motion animation\", \"Van Gogh\", \"Surrealist painting\", \"Monochromatic black and white\", \"Vibrant and saturated\", \"Film noir style\", \"High-key lighting\", \"Low-key lighting\", \"Golden hour glow\", \"Volumetric lighting\", \"Backlighting to create a silhouette\"]\n",
        "\n",
        "num_items = 10 #@param {type:\"integer\", min:1, max:10}"
      ],
      "metadata": {
        "id": "7eT2WJIbWDwD"
      },
      "id": "7eT2WJIbWDwD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Veo Prompts Using User-Provided Parameters\n",
        "---"
      ],
      "metadata": {
        "id": "ZAMY_EYb_DRL"
      },
      "id": "ZAMY_EYb_DRL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get lists of items that fit subject and scene themes"
      ],
      "metadata": {
        "id": "HIlmLNusOpb2"
      },
      "id": "HIlmLNusOpb2"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_list_of_items_that_fit_theme(num_items, theme):\n",
        "\n",
        "    list_generation_system_instruction = types.Part.from_text(text=\"\"\"\n",
        "    You are an expert list creator, who can create lists of various sizes that\n",
        "    fit a specific theme.\n",
        "\n",
        "    Make sure that each item returned is real and fits within the theme, and\n",
        "    references the subject theme in the result - e.g. \"vanilla ice cream\"\n",
        "    instead of just \"vanilla.\"\n",
        "\n",
        "    Make sure the visual description captures essential elements of how an item\n",
        "    of this theme would show up visually (e.g. ice cream in a bowl or cone).\n",
        "\n",
        "    Rank the items based on the prevalence, popularity, quality, or otherwise\n",
        "    superiority of the items (with criteria depending on the list theme).\n",
        "\n",
        "    Only return the list of items in ranked order along a visual description of\n",
        "    each item, no other text.\n",
        "    \"\"\")\n",
        "\n",
        "    ranked_list_response_schema = {\n",
        "      \"type\": \"ARRAY\",\n",
        "      \"items\": {\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "          \"item\": {\n",
        "            \"type\": \"STRING\"\n",
        "          },\n",
        "          \"visual_description\": {\n",
        "            \"type\": \"STRING\"\n",
        "          },\n",
        "          \"rank\": {\n",
        "            \"type\": \"STRING\",\n",
        "            \"enum\": [str(i) for i in range(1, num_items + 1)]\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\n",
        "          \"item\",\n",
        "          \"visual_description\",\n",
        "          \"rank\"\n",
        "          ]\n",
        "      }\n",
        "    }\n",
        "\n",
        "    list_generation_config = types.GenerateContentConfig(\n",
        "      temperature = 1,\n",
        "      top_p = 0.95,\n",
        "      max_output_tokens = 8192,\n",
        "      system_instruction = [list_generation_system_instruction],\n",
        "      response_modalities = [\"TEXT\"],\n",
        "      response_mime_type = \"application/json\",\n",
        "      response_schema = ranked_list_response_schema\n",
        "      )\n",
        "\n",
        "    list_generation_prompt = types.Part.from_text(text=\n",
        "    f\"Create a list of {num_items} that fit the theme of {theme}.\")\n",
        "\n",
        "    list_generation_response = client.models.generate_content(\n",
        "      model=gemini_model,\n",
        "      contents=list_generation_prompt,\n",
        "      config=list_generation_config\n",
        "      )\n",
        "\n",
        "    list_generation_response_text = list_generation_response.text\n",
        "\n",
        "    return(list_generation_response_text)\n",
        "\n",
        "gemini_subject_items_list = get_list_of_items_that_fit_theme(num_items,\n",
        "  subject_theme)\n",
        "\n",
        "print(gemini_subject_items_list)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "gemini_scene_items_list = get_list_of_items_that_fit_theme(num_items,\n",
        "  scene_theme)\n",
        "\n",
        "print(gemini_scene_items_list)"
      ],
      "metadata": {
        "id": "T3gzTAPf-Sbr"
      },
      "id": "T3gzTAPf-Sbr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get prompts for Veo that combine subjects, scenes, and style"
      ],
      "metadata": {
        "id": "ND62y6nvO-vX"
      },
      "id": "ND62y6nvO-vX"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_prompt(subject, subject_visual_description, scene,\n",
        "  scene_visual_description, style):\n",
        "\n",
        "    gemini_video_prompt = f\"\"\"\n",
        "    You are an expert video prompt engineer for Google's Veo model.\n",
        "    Your task is to construct the most effective and optimal prompt string\n",
        "    that showcases the subject {subject}, as described by\n",
        "    {subject_visual_description}, in the scene {scene}, as described by\n",
        "    {scene_visual_description}, using a {style} style.\n",
        "\n",
        "    Synthesize these pieces into a single, cohesive, and cinematic instruction.\n",
        "    Make sure that the size of the subject is appropriate relative to the scene.\n",
        "    Add in instructions for relevant audio, whether that be human speech,\n",
        "    background noise, music, or other sound effects.\n",
        "\n",
        "    Do not add any other new concepts. Output ONLY the final prompt string,\n",
        "    without any introduction or explanation.\n",
        "    \"\"\"\n",
        "\n",
        "    gemini_video_prompt_response = client.models.generate_content(\n",
        "        model=gemini_model,\n",
        "        contents=gemini_video_prompt,\n",
        "    )\n",
        "\n",
        "    return gemini_video_prompt_response.text\n",
        "\n",
        "items_and_scenes_combined = pd.merge(\n",
        "  pd.DataFrame(json.loads(gemini_subject_items_list)).\n",
        "    assign(random = np.random.permutation(np.arange(1, num_items+1))),\n",
        "  pd.DataFrame(json.loads(gemini_scene_items_list)).\n",
        "    assign(random = np.random.permutation(np.arange(1, num_items+1))),\n",
        "  on = \"random\",\n",
        "  suffixes = (\"_subject\", \"_scene\")\n",
        "  ).drop(columns = [\"random\"])\n",
        "\n",
        "def apply_generate_video_prompt_to_row(row):\n",
        "  return generate_video_prompt(row['item_subject'],\n",
        "    row['visual_description_subject'], row['item_scene'],\n",
        "    row['visual_description_scene'], style)\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "  video_prompts = list(executor.map(apply_generate_video_prompt_to_row,\n",
        "    items_and_scenes_combined.to_dict('records')))\n",
        "\n",
        "items_and_scenes_combined['video_prompt'] = video_prompts\n",
        "\n",
        "display(items_and_scenes_combined)"
      ],
      "metadata": {
        "id": "znSJvOD2Pfv5"
      },
      "id": "znSJvOD2Pfv5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Videos for Each Prompt\n",
        "----"
      ],
      "metadata": {
        "id": "oir9Owg1_NuP"
      },
      "id": "oir9Owg1_NuP"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_video_from_prompt(video_prompt):\n",
        "\n",
        "  video_gen_operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=video_prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "      aspect_ratio=\"16:9\",\n",
        "      number_of_videos=1,\n",
        "      duration_seconds=8,\n",
        "      resolution=\"1080p\",\n",
        "      person_generation=\"allow_adult\",\n",
        "      enhance_prompt=True,\n",
        "      generate_audio=True\n",
        "      )\n",
        "    )\n",
        "\n",
        "  print(f\"Starting video generation with prompt:\\n {video_prompt}\\n\")\n",
        "\n",
        "  while not video_gen_operation.done:\n",
        "    time.sleep(15)\n",
        "    video_gen_operation = client.operations.get(video_gen_operation)\n",
        "    print(\"Video generation in progress\")\n",
        "\n",
        "  if video_gen_operation.response:\n",
        "    gen_video = video_gen_operation.result.generated_videos[0].video\n",
        "\n",
        "    return gen_video\n",
        "\n",
        "def generate_video_for_row(row):\n",
        "  return generate_video_from_prompt(row['video_prompt'])\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "  videos = list(executor.map(generate_video_for_row,\n",
        "    items_and_scenes_combined.to_dict('records')))\n",
        "\n",
        "items_and_scenes_combined['video'] = videos\n",
        "\n",
        "display(items_and_scenes_combined)"
      ],
      "metadata": {
        "id": "4luMYhMy_Sal"
      },
      "id": "4luMYhMy_Sal",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting Things Together and Outputting\n",
        "---"
      ],
      "metadata": {
        "id": "02aeVZA_AP6Y"
      },
      "id": "02aeVZA_AP6Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Put all prompts together into 1 text string"
      ],
      "metadata": {
        "id": "ABpuekGztYA2"
      },
      "id": "ABpuekGztYA2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Limit down to items and scenes where actual video was generated\n",
        "items_and_scenes_with_video = (items_and_scenes_combined[\n",
        "  ~pd.isna(items_and_scenes_combined['video'])].\n",
        "  reset_index(drop = True)\n",
        "  )\n",
        "\n",
        "all_items_scenes_prompts = \"\"\n",
        "\n",
        "for index, row in items_and_scenes_with_video.iterrows():\n",
        "  all_items_scenes_prompts += (\n",
        "  f\"Video {index + 1}\\n\"\n",
        "  f\"Subject: {row['item_subject']}\\n\"\n",
        "  f\"Scene: {row['item_scene']}\\n\"\n",
        "  f\"Prompt: {row['video_prompt']}\\n\\n\\n\"\n",
        "  )\n",
        "\n",
        "print(all_items_scenes_prompts)\n",
        "\n",
        "with open('all_items_scenes_prompts.txt', 'w') as f:\n",
        "  f.write(all_items_scenes_prompts)"
      ],
      "metadata": {
        "id": "tPEDqQMYtWwK"
      },
      "id": "tPEDqQMYtWwK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos_list = items_and_scenes_with_video['video'].tolist()\n",
        "\n",
        "# Create a directory to store the individual video files\n",
        "!mkdir -p /videos\n",
        "\n",
        "for i, video in enumerate(videos_list):\n",
        "  with open(f\"/videos/video_{i+1}.mp4\", \"wb\") as f:\n",
        "    f.write(video.video_bytes)\n",
        "\n",
        "# Create a file containing the list of video files\n",
        "with open(\"/videos/video_list.txt\", \"w\") as f:\n",
        "  for i in range(len(videos_list)):\n",
        "    f.write(f\"file '/videos/video_{i+1}.mp4'\\n\")\n",
        "\n",
        "# Concatenate the videos using ffmpeg\n",
        "!ffmpeg -f concat -safe 0 -i /videos/video_list.txt -c copy combined_video.mp4"
      ],
      "metadata": {
        "id": "McdBG1ys_Sey"
      },
      "id": "McdBG1ys_Sey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Output Files"
      ],
      "metadata": {
        "id": "nis3hUrLhJLF"
      },
      "id": "nis3hUrLhJLF"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('all_items_scenes_prompts.txt')\n",
        "files.download('combined_video.mp4')"
      ],
      "metadata": {
        "id": "XkXwOBPYhAly"
      },
      "id": "XkXwOBPYhAly",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the combined video\n",
        "show_video(\"combined_video.mp4\")"
      ],
      "metadata": {
        "id": "47aI1Swvu7n9"
      },
      "id": "47aI1Swvu7n9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "generate_combined_veo3_videos_by_theme_using_api"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
